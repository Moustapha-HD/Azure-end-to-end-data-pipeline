{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97aca3a-8cc2-4ecf-b023-5fb80b1e889b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: True"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://<container-name>@<storage-account-name>.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/<mount-name>\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245b458a-bc44-4e70-99ee-b5a97097fb53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: [FileInfo(path='dbfs:/mnt/bronze/HumanResources/Department/', name='Department/', size=0, modificationTime=1694762435000),\n FileInfo(path='dbfs:/mnt/bronze/HumanResources/Employee/', name='Employee/', size=0, modificationTime=1694762435000),\n FileInfo(path='dbfs:/mnt/bronze/HumanResources/EmployeeDepartmentHistory/', name='EmployeeDepartmentHistory/', size=0, modificationTime=1694762438000),\n FileInfo(path='dbfs:/mnt/bronze/HumanResources/EmployeePayHistory/', name='EmployeePayHistory/', size=0, modificationTime=1694762437000),\n FileInfo(path='dbfs:/mnt/bronze/HumanResources/JobCandidate/', name='JobCandidate/', size=0, modificationTime=1694762438000),\n FileInfo(path='dbfs:/mnt/bronze/HumanResources/Shift/', name='Shift/', size=0, modificationTime=1694762437000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/bronze/HumanResources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3263730d-f058-4c6e-bcbb-86ce36cd762c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: True"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://<container-name>@<storage-account-name>.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/<mount-name>\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68aa774a-7832-43c1-8337-567d3cf70dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: []"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9342ce09-4b9b-4350-96b8-1a5f61fa9440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: True"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://<container-name>@<storage-account-name>.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/<mount-name>\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa5905ee-5e1a-4c9a-9e23-b38bd8a30f37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/mnt/gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "storage_mount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
